on: [push, pull_request]

name: Continuous integration

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  check:
    name: Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
        with:
          key: check-${{ runner.os }}
      - run: |
          make check
          make check-migrate
          make check-dirty-rpc-doc

  cargo-shear:
    name: Cargo Shear
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
        with:
          key: shear-${{ runner.os }}
      - uses: cargo-bins/cargo-binstall@main
      - run: |
          cargo binstall --no-confirm cargo-shear --force --locked --version 1.1.9
          cargo shear

  test:
    name: Test
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v4
      - name: Check for code changes
        uses: dorny/paths-filter@v3
        id: changes
        with:
          filters: |
            code:
              - 'crates/**'
              - 'fiber-js/**'
              - 'tests/**'
              - 'Cargo.*'

      - name: Skip tests if no code changes
        if: steps.changes.outputs.code != 'true'
        run: |
          echo "üöÄ No code changes detected in crates/, fiber-js/, or tests/"
          echo "Skipping unit tests to save CI resources."
          exit 0

      - uses: dsherret/rust-toolchain-file@v1
        if: steps.changes.outputs.code == 'true'
      - uses: Swatinem/rust-cache@v2
        if: steps.changes.outputs.code == 'true'
        with:
          key: test-${{ runner.os }}
      - uses: taiki-e/install-action@v2
        if: steps.changes.outputs.code == 'true'
        with:
          tool: nextest
      - name: Run tests
        if: steps.changes.outputs.code == 'true'
        run: |
          RUST_BACKTRACE=full RUST_LOG=trace,fnn=trace,fnn::cch::actor::tracker=off,fnn::fiber::gossip=off,tentacle=off,tokio_yamux=off,tentacle_secio=off cargo nextest run --no-fail-fast
        env:
          RUST_TEST_THREADS: 2

  fmt:
    name: Rustfmt
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
        with:
          key: fmt-${{ runner.os }}
      - run: cargo fmt --all -- --check

  clippy:
    name: Clippy
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
        with:
          key: clippy-${{ runner.os }}
      - run: |
          rustup target add wasm32-unknown-unknown
          make clippy

  typos:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
      - name: Check for typos
        uses: crate-ci/typos@v1.30.0
      - name: Typos info
        if: failure()
        run: |
          echo 'To fix typos, please run `cargo install typos && typos -w`'
          echo 'To check for a diff, run `typos`'
          echo 'You can find typos here: https://crates.io/crates/typos'
          echo 'if you use VSCode, you can also install `Typos Spell Checker'
          echo 'You can find the extension here: https://marketplace.visualstudio.com/items?itemName=tekumara.typos-vscode'

  coverage:
    name: Code Coverage
    needs: [ test ]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    steps:
      - uses: actions/checkout@v4

      - name: Check for code changes
        uses: dorny/paths-filter@v3
        id: changes
        with:
          filters: |
            code:
              - 'crates/**'
              - 'fiber-js/**'
              - 'tests/**'
              - 'Cargo.*'

      - name: Skip coverage if no code changes
        if: steps.changes.outputs.code != 'true'
        run: |
          echo "üöÄ No code changes detected in crates/, fiber-js/, or tests/"
          echo "Skipping coverage test to save CI resources."
          exit 0

      - uses: dsherret/rust-toolchain-file@v1
        if: steps.changes.outputs.code == 'true'
      - uses: Swatinem/rust-cache@v2
        if: steps.changes.outputs.code == 'true'
        with:
          key: coverage-${{ runner.os }}
      - name: Install Grcov
        if: steps.changes.outputs.code == 'true'
        run: make coverage-install-tools
      - name: Generate Code Coverage Report of Unit Tests
        if: steps.changes.outputs.code == 'true'
        run: |
          make coverage-run-unittests
          make coverage-collect-data
      - name: Upload Code Coverage Report of Unit Tests
        if: steps.changes.outputs.code == 'true'
        uses: codecov/codecov-action@v4
        with:
          files: coverage-report.info
          env_vars: OS,RUST_TOOLCHAIN
          fail_ci_if_error: false
          flags: unittests
          verbose: false
          token: ${{ secrets.CODECOV_TOKEN }}

  build:
    name: Build
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        profile: [dev, release]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    timeout-minutes: 45
    steps:
      - uses: actions/checkout@v4
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
        with:
          key: build-${{ matrix.os }}-${{ matrix.profile }}
      - name: Install Dependencies (Windows)
        if: contains(matrix.os, 'windows')
        run: |
          vcpkg integrate install
          vcpkg install openssl:x64-windows-static-md
      - name: Build with profile
        run: cargo build --locked --verbose --profile ${{ matrix.profile }}


  benchmark:
    name: Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 90
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
      - name: Setup Dependencies
        uses: ./.github/actions/setup-dependencies
        with:
          ckb-version: '0.116.1'
          cache-prefix: 'benchmark'

      - name: Cache build artifacts
        uses: actions/cache@v4
        with:
          path: |
            ./tests/deploy/udt-init/target
            ./tests/perf/target
          key: build-artifacts-${{ runner.os }}-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            build-artifacts-${{ runner.os }}-

      - name: Build rust code
        run: |
          cd ./tests/deploy/udt-init && cargo build --locked && cd -
          cd ./tests/perf/ && cargo build --release --locked && cd -

      - name: Cache baseline benchmark results
        uses: actions/cache@v4
        id: cache-baseline
        with:
          path: |
            ./tests/perf/baseline.json
            ./baseline.log
          key: baseline-${{ github.base_ref }}-${{ hashFiles('tests/**/*.rs', 'crates/**/*.rs') }}
          restore-keys: |
            baseline-${{ github.base_ref }}-

      - name: Get baseline benchmark
        if: steps.cache-baseline.outputs.cache-hit != 'true'
        run: |
          echo "Comparing against: origin/${{ github.base_ref }}"
          git checkout origin/${{ github.base_ref }}

          sed -i 's/sleep 5/sleep 10/g' ./tests/nodes/wait.sh || true
          export ON_GITHUB_ACTION=y
          CKB_LOG=warn TEST_ENV=release ./tests/nodes/start.sh > baseline.log 2>&1 &
          ./tests/nodes/wait.sh

          cd ./tests/perf/
          cargo run --bin run-test --release integration
          cargo run --bin run-test --release benchmark 90 30 base
          cd -
          git stash

      - name: Restore baseline results (if cached)
        if: steps.cache-baseline.outputs.cache-hit == 'true'
        run: |
          echo "‚úÖ Using cached baseline benchmark results"
          ls -la ./tests/perf/baseline.json || echo "Baseline file not found in cache"

      - name: Run current benchmark
        run: |
          echo "Running benchmark on current PR commit: ${{ github.sha }}"
          git checkout ${{ github.sha }}

          pkill -f 'fnn|ckb run|npm' || true
          rm -rf ./tests/nodes/.ports
          export ON_GITHUB_ACTION=y
          REMOVE_OLD_STATE=y CKB_LOG=warn TEST_ENV=release ./tests/nodes/start.sh > current.log 2>&1 &
          ./tests/nodes/wait.sh

          cd ./tests/perf/
          cargo run --bin run-test --release integration
          cargo run --bin run-test --release benchmark 90 30 compare
          cd -

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            ./baseline.log
            ./current.log
            ./tests/perf/comparison_report.txt
            ./tests/perf/baseline.json
            ./tests/perf/current.json

      - name: Check benchmark result
        run: |
          echo "Check benchmark result on current PR commit: ${{ github.sha }}"
          if [ -f "./tests/perf/comparison_report.txt" ]; then
            if grep -q "Performance regression detected" "./tests/perf/comparison_report.txt"; then
              echo "‚ùå Performance regression detected! Failing the workflow."
              exit 1
            else
              echo "‚úÖ No performance regression detected."
            fi
          else
            echo "‚ö†Ô∏è Comparison report not found at ./tests/perf/comparison_report.txt"
            echo "This might indicate a benchmark execution failure."
            exit 1
          fi

  # Summary job that depends on all other jobs
  ci-success:
    name: CI Success
    runs-on: ubuntu-latest
    needs: [check, cargo-shear, test, fmt, clippy, typos]
    if: always()
    steps:
      - name: Check all job results
        run: |
          if [[ "${{ needs.check.result }}" == "success" && \
                "${{ needs.cargo-shear.result }}" == "success" && \
                "${{ needs.test.result }}" == "success" && \
                "${{ needs.fmt.result }}" == "success" && \
                "${{ needs.clippy.result }}" == "success" && \
                "${{ needs.typos.result }}" == "success" ]]; then
            echo "üéâ All CI checks passed!"
            exit 0
          else
            echo "‚ùå Some CI checks failed:"
            echo "  - Check: ${{ needs.check.result }}"
            echo "  - Cargo Shear: ${{ needs.cargo-shear.result }}"
            echo "  - Test: ${{ needs.test.result }}"
            echo "  - Format: ${{ needs.fmt.result }}"
            echo "  - Clippy: ${{ needs.clippy.result }}"
            echo "  - Typos: ${{ needs.typos.result }}"
            exit 1
          fi
